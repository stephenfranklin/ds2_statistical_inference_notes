\documentclass{article}
%%%%% statistical_inference.Rnw
%%%%% LaTeX / Sweave notes by Stephen Franklin, May 2014,
%%%%% for Statistical Inference - Coursera / Johns Hopkins - Prof. Brian Caffo

%%%%%% my custom command definitions %%%%%%

%% \mathbf sucks because it screws up other math mode directives.  Instead
%% use \boldsymbol (from AMS) since it puts stuff in bold italics.
\newcommand{\bsymb}[1]{\boldsymbol{#1}}
\newcommand{\bea}{\begin{eqnarray*}}
\newcommand{\eea}{\end{eqnarray*}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\si}{\subitem}
\newcommand{\ssi}{\subsubitem}
\newcommand{\tn}{\textnormal}  % in math mode text will use font of document.
    %% \textrm = roman font, \tt=\texttt = typewriter font

\begin{document}
\SweaveOpts{concordance=TRUE}

\section*{Statistical Inference Notes}
Statistical Inference is the process of drawing formal conclusions;
as settings where one wants to infer facts about a population using noisy statistical data where uncertainty must be accounted for.\\
\\
A strong inference may affect the study itself. Researchers may decide it is ethically responsible to halt the study in light of strongly positive or negative preliminary results.

\subsection*{Considerations of a study include:}
\begin{itemize}
    \item Is the sample representative of the target population?
    \item Is the sample representative of the target population?
    \item Are there known and observed, known and unobserved, or unknown and unobserved variables that contaminate our conclusions?
    \item Is there systematic bias created by missing data or the design or conduct of the study?
    \item What randomness exists in the data and how do we use or adjust for it?  
        \subitem Randomness can be explicit via randomization or random sampling,
        \subitem or implicit as the aggregation of many complex unknown processes.
    \item Are we trying to estimate an underlying mechanistic model of phenomena under study?
\end{itemize}

\subsection*{Example goals of Inference:}
\begin{itemize}
    \item Estimate or quantify the uncertainty of an estimate.
    \item Determine whether the quantity is a benchmark value ("Is the treatment effective?")
    \item Infer a mechanistic relationship when quantities are measured with noise ("What is the slope for Hooke's Law?")
    \item Determine the overall impact of a policy a phenomenon, as opposed to revealing the mechanism that describes it.
\end{itemize}

\subsection*{Some tools of the trade:}
\begin{itemize}
    \item Randomization: balances unobserved variables that may confound inferences, i.e between the control and treated.
    \item Random Sampling: data obtained is representative of the population of interest.
    \item Sampling models: a model for the sampling process is created because Randomization and Random Sampling are often impossible. "iid".
    \item Hypothesis Testing: Decision making in the presence of uncertainty.
    \item Confidence Intervals: Quantify the uncertainty in estimation.
    \item Probability Models: A formal connection between the data and the population of interest; assumed or approximated.
    \item Study Design: Designing the experiment to minimize bias and variability. Of course randomized is the best.
    \item Nonparametric Bootstrapping: The process of using the data (with minimal Probability Model assumptions) to create inferences.
    \item Permutation, Randomization, and Exchangability Testing: The process of using data permutations to perform inferences.
\end{itemize}

\subsection*{Thinking Styles:}
Data scientists use some combination of two opposing modes of inference (as well as other schools of thought):
\begin{itemize}
    \item Frequency Inference: What should I decide given the long-run-proportion of events in independent, identically distributed repetitions?
    \item Bayesian Inference: Given my subjective beliefs, and the new objective information from the data, how should I modify my beliefs?
\end{itemize}

This class will focus on frequency style analyses, beginning with probability modeling.

\section*{Probability}
\subsection*{Notation}
\begin{itemize}
    \item $\Omega$: The sample space; the collection of all possible outcomes.
        \subitem e.g. die roll: $\Omega = \{1,2,3,4,5,6\}$
    \item $E$: (Or another letter.) An event; a subset of $\Omega$.
        \subitem e.g. die roll is even: $E = \{2,4,6\}$
    \item $\omega$: (Or another letter.) An elementary or simple event is a particular result of an experiment.
        \subitem e.g. die roll is a four: $\omega = 4$
    \item $\emptyset$: The null event or empty set.
\end{itemize}

\subsection*{Common Set Operations}
\bi
\item $\omega \in E$: The simple event $\omega$ is an element of set $E$.  
    \subitem Implies that $E$ occurs when $\omega$ occurs.
    \subitem e.g. If I rolled a 4, then I rolled an even number.  
\item $\omega \notin E$: The simple event is not an element of the set.
    \subitem Implies that $E$ doesn't occur when $\omega$ occurs.
\item $E \subset F$: The set $E$ is a subset of set $F$.
    \subitem The occurrence of $E$ implies the occurrence of $F$.
\item $E \cap F$: Intersection; the set containing the elements that are common to both $E$ and $F$.
    \subitem Implies an event for which both $E$ and $F$ occur.
\item $E \cup F$: Union; the set containing all the elements in both $E$ and $F$.
    \subitem Implies an event for which $E$ or $F$ or both occur.
\item $E \cap F = \emptyset$: $E$ and $F$ are mutually exclusive; both cannot occur; no intersection.
\item $E^c$ or $\bar{E}$: The event for which $E$ doesn't occur.
\ei

\subsection*{Probability}
A probability measure, $P$, is a function from the sample space $\Omega$ for which the following hold true:\\
\begin{enumerate}
\item For an event $E \subset \Omega, 0 \le P(E) \le 1$.
    \subitem For an event in a subset of the sample space, 
    \subitem the probability is between 0 and 1.
\item $P(\Omega) = 1$.
    \subitem The probability of an event in the entire sample space is 1.
\item If $E_1 \cap E_2 = \emptyset, P(E_1 \cup E_2) = P(E_1) + P(E_2)$.
    \subitem If $E_1$ and $E_2$ have no intersection,
    \subitem then the probability of their union is the sum of their probabilities.
\item \#3 implies finite additivity:
    $$P(\cup^n_{i=1}A_i)=\sum_{i=1}^{n} P(A_i)$$
    \subitem where the ${A_i}$ are mutually exclusive.
    \subitem If you union up a bunch of mutually exclusive events,
    \subitem then the union can become a sum.
\end{enumerate}

\subsection*{Example Consequences}
Andrey Nikolaevich Kolmogorov in 1933 formulated these eight axioms and said that these are all you need to have probability behave as we think it should.
\bi
\item $P(\emptyset)=0$
    \subitem also $P(\Omega)=1$
\item $P(E)=1-P(\bar{E})$
\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\item if $A \subset B$ then $P(A) \le P(B)$
\item $P(A \cup B) = 1-P(\bar{A} \cap \bar{B})$
\item $P(A \cap \bar{B}) = P(A) - P(A \cap B)$
\item $P(\cup^n_{i=1} E_i) \le \sum_{i=1}^n P(E_i)$
\item $P(\cup^n_{i=1} E_i) \ge \tn{max}_i P(E_i)$
\ei

\subsection*{Random Variables}
\begin{enumerate}
\item discrete: $P(X=k)$
\item continuous: $P(X \in A)$
\end{enumerate}

\subsection*{PMF - Probability Mass Function}
The probability mass function describes a discrete random variable. A PMF evaluated at a value corresponds to the probability that a random variable takes that value. To be a valid PMF, a function $p$ must satisfy:
\begin{enumerate}
\item $p(x) \ge$ for all $x$.
\item $\sum_x p(x) =1$
\end{enumerate}
where the sum is taken over all possible values for $x$.

\subsubsection*{Example 1:}
Let $X$ be the result of a coin flip where $X=\{0,1\}$ or \{heads,tails\}.
\bea
p(x) &=& (1/2)^x (1/2)^{1-x} \tn{ for } x=0,1 \\
p(1) &=& (1/2)^1 (1/2)^{1-1} \ = \ 1/2 \\
p(0) &=& (1/2)^0 (1/2)^{1-0} \ = \ 1/2
\eea

\subsubsection*{Example 2:}
Suppose the coin isn't fair. Let $\theta$ be the probability of a head expressed as a proportion (between 0 and 1), say 0.25.
\bea
p(x) &=& \theta^x (1-\theta)^{1-x} \tn{ for } x=0,1 \\
p(1) &=& \theta^1 (1-\theta)^{1-1} \ = \ \theta \\
p(0) &=& \theta^0 (1-\theta)^{1-0} \ = \ 1-\theta
\eea
So if heads is $\theta = 0.25$, then tails is $1-0.25 = 0.75$.

\subsection*{PDF - Probability Density Function}
The probability density function describes a continuous random variable. The area under the PDF line corresponds to a probability for a group of values of the variable.\\
To be a valid PDF, a function $f$ must satisfy:
\begin{enumerate}
\item $f(x) \ge$ for all $x$.
\item The area under $f(x)$ is one.
\end{enumerate}
A single value of a continuous random variable corresponds to an area of 0.\\
Instead, we refer to a probability of a region of values (between $a$ and $b$).
The fact that the probability of a single specific value is 0 is a consequence of modeling the probability as a truly continuous entity, an infinite decimal expansion, wherein we cannot attain infinite precision. In other words, there is no such thing as a single specific value.\\
\\
The Gaussian Bell Curve is the most famous example of a probability density function.

\subsubsection*{Example 1:}
Suppose that the proportion of help calls that get addressed in a random day by a help line is given by this probability density:
$$
f(x) = \left\{ \begin{array}{rl}
 2x &\mbox{ for $1 > x > 0$} \\
 0 &\mbox{ otherwise}
        \end{array} \right.
$$
Is this a mathematically valid density?
<<pdf_example_1, fig=T, echo=T >>=
x <- c(-0.5, 0, 1, 1, 1.5)
y <- c(0, 0, 2, 0, 0)
#par(pin = c(2,2), mar = (c(2, 2, 2, 1) + 0.1))
plot(x,y, lwd=3, frame=F, type="l")
abline(v=0.5)
abline(v=0.75)
@
\\
If we ask "What percentage of days do between 50\% and 75\% of the calls get addressed?," then the area under within the lines corresponds to the percentage of days that that range of calls get addressed.\\
\\
It's roughly $0.25 \cdot 1.25 = 0.31$ or \\
"31\% of the time (in days) between 50\% and 75\% of calls are addressed on a day."

\subsubsection*{Example 2:}
What is the probability that 75\% or fewer calls get addressed?
<<pdf_example_2, fig=T, echo=T >>=
x <- c(-0.5, 0, 1, 1, 1.5)
y <- c(0, 0, 2, 0, 0)
#par(pin = c(2,2))
plot(x,y, lwd=3, frame=F, type="l")
abline(v=0)
abline(v=0.75)
@
\\
The area is $0.5 (0.75 \cdot 1.5) = 0.5625$. \\
\\
In R, the command \emph{pbeta()} of x will return the probability of being lower than x:
<<echo=T>>=
pbeta(0.75, 2, 1)
@

\subsection*{CDF and Survival Function}
The Cumulative Distribution Function of a random variable $X$ is defined as the function:
$$F(x) = P(X \le x)$$
This definition applies to both discrete and continuous variables.\\
\\
The Survival Function of a random variable $X$ is defined as:
$$S(x) = P(X > x)$$
Notice that $S(X) = 1 - F(X)$.\\
\\
For continuous variables the PDF is the derivative of the CDF.

\subsubsection*{Example:}
What are the Survival Function and the CDF from the density considered previously?\\
\\
For $1 \ge x \ge 0$ \\
(We must exclude unanswered calls, i.e. outside of $x=[0,1]$, for this density to make sense),
\bea
F(x)    &=& P(X \le x) \ =\  \frac{1}{2} \ base \times height \\
        &=& \frac{1}{2} (x) \times (2x) \ = \ x^2 \\
S(x)    &=& 1-x^2
\eea
\\
In R, we can use the \emph{pbeta()} function to get the probabilities:\\
<<echo=TRUE>>=
pbeta(c(0.4,0.5,0.6), 2, 1)
@

\subsection*{Quantiles}
The $\alpha^{th}$ quantile of a distribution with the distribution function $F$ is the point $x_{\alpha}$ so that:
$$F(x_{\alpha}) = \alpha$$
A percentile is simply a quantile with $\alpha$ expressed as a percent. \\
\\
The median is the $50^{th}$ percentile, or the $0.5^{th}$ quantile, and can be expressed as $x_{0.5}$. \\
\\
Consider that 0.5 of the area lies below $x_{0.5}$ and 0.5 of the area lies above it. We can express that as: $0.5 = F(x_{0.5})$. \\
\\
Recall that the cumulative distribution function for our example is $F = x^2$. \\
To find $x_{0.5}$, we must invert the function $F$.
\bea
x \ = \ F^{-1}(x) \ = \ \sqrt{x} \\
x_{0.5} \ = \ \sqrt{0.5} \ = \ 0.707
\eea \\
Therefore, about 70\% of calls being answered on a random day is the median.\\
\\
In general, the distribution function describes a point $x_{\alpha}$ along a density for which the area $\alpha$ lies below it, and the area $1-\alpha$ lies above it.\\
\\
In R, we can approximate the quantiles for common distributions with the function \emph{qbeta()}:
<<echo=TRUE>>=
qbeta(0.5,2,1)
@
\subsection*{Probability Summary}
A probability model uses assumptions to connect the sample data (which is limited) to the population.  We want connect the sample median to the population median; the population median is the estimand, and the sample median is the estimator.

\section*{Expected Values - Discrete Random Variables}
The Expected Value is the mean of a random variable, and is the center of its distribution.\\
\\
For a discrete random variable $X$ with PMF p(x), it is defined as:
$$E[X] = \sum_x xp(x)x$$
\\
We use the square brackets [] to denote the expected value.\\
\\
$E[X]$ represents the center of mass of a collection of locations and weights, $\{x,p(x)\}$.

\subsubsection*{Example - R Library Manipulate}
<<example_manipulate,echo=TRUE,>>=
library(manipulate)
galton<-read.csv("Galton.csv")
myHist <- function(mu){
    hist(galton$child, col="blue", breaks=100)
    lines(c(mu,mu), c(0,150), col="red", lwd=5)
    mse <- mean((galton$child -mu)^2 )
    text(63,150, paste("mu = ",mu ))
    text(63,140, paste("Imbalance = ", round(mse,2) ))
}
#manipulate(myHist(mu), mu=slider(62,74, step=0.5))
@
The manipulate() library makes interactive plots, so it won't work in this .pdf document, but the histogram looks like this:\\
<<echo=F, fig=TRUE>>=
    #galton<-read.csv("Galton.csv")
    hist(galton$Child, col="blue", breaks=100)
    meanChild <- mean(galton$Child)
    lines(rep(meanChild, 100), seq(0,150, length=100), col="red", lwd=5)
@

\subsubsection*{Example - expected value of a discrete variable}
Suppose that a die is rolled and X is the number that is face up. \\
What is the expected value of X?\\
\\
$$E[X] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5$$

\subsection*{Expected Value - Continuous Random Variables}
For a continuous random variable $X$ with a density $f$ the expected value is defined as:
$$E[X] = \tn{ the area under the function } tf(t)$$
This definition borrow from the definition of center of mass for a continuous body.

\subsubsection*{Example - expected value of a continuous variable}
Consider a density where $f(x) = 1$ for $x$ between 0 and 1.\\
Is this a valid density?\\
Suppose $X$ follows this density. What is its expected value?\\
\\
$f(x)$ describes a block shaped density.\\
It's valid because $y > 0$ everywhere that $x$ is positive,\\
and it has a calculable area (base x height = 1 x 1 = 1).\\
\\
The function $tf(t)$ in this case is a right triangle where $x=y$.\\
We can integrate that to find the area, or we can simply compute the area  of a triangle: (1/2 x base x height = 0.5).\\
So 0.5 is the mean and the expected value, and it is also intuitively the center of mass for the block.

\subsection*{Rules of Expected Values}
\bi
\item The expected value is a linear operator.
\item If $a$ and $b$ are not random and $X$ and $Y$ are two random variables, then:
    \subitem $E[aX+b] = aE[X]+b$
    \subitem $E[X+Y] = E[X]+E[Y]$
\item but:
    \subitem $E[X \cdot Y] \ne E[X] \cdot E[Y]$
    \subitem $E[X^2] \ne E[X]^2$
\ei

\subsubsection*{examples - rules of expected values}
You flip a coin $X$ and simulate a uniform random number $Y$.\\
What is the expected value of their sum?\\
\\
The random uniform density is the block-like density which yields numbers between 0 and 1; the expected value of the uniform density is 0.5.\\
The coin flip yields only 0 or 1, and its expected value is also 0.5.
$$E[X+Y] = E[X]+E[Y] = 0.5 + 0.5 = 1$$\\
You roll a die twice. What is the expected value of the average? \\
\\
Let $X_1$ and $X_2$ be the results of two dice rolls. The average of course is their sum divided by their count.
$$E[(X_1+X_2)/2] = \frac{1}{2}(E[X_1]+E[X_2]) = \frac{1}{2}(3.5 + 3.5) = 3.5$$
\\
That case can be generalized:\\
Let $X_i$ for $i = 1, ..., n$ be a collection of random variables, each from a distribution  with mean $\mu$. \\
Then the expected value of the sample average of $X_i$ is found by:
\bea
E \left[ \frac{1}{n} \sum_{i=1}^n X_i \right]
&=& \frac{1}{n} E \left[ \sum_{i=1}^n X_i \right] \\
&=& \frac{1}{n} \sum_{i=1}^n E \left[ X_i \right] \\
&=& \frac{1}{n} \sum_{i=1}^n \mu = \mu
\eea
So if all the variables have the same mean, then their average also has that mean.\\
Therefore, the expected value of the sample average is the population mean as well; it's exactly what we would like it to be.\\
When the expected value of an estimator is what it is trying to estimate, we say that the estimator is unbiased.

\subsection*{Variance}
The variance of a random variable is a measure of spread.\\
\\
If $X$ is a random variable with mean $\mu$, the variance is defined as:
$$Var(X) = E[(X-\mu)^2]$$
the expected (squared) distance from the mean.\\
\\
Densities with a higher variance are more spread out then densities with lower variance.\\
\\
Computational form:
$$Var(X) = E[X^2] - E[X]^2$$
\\
If $a$ is constant then $Var(aX) = a^2 Var(X)$.\\
If you pull a constant out of a variance, the constant gets squared.\\
\\
The square root of the variance is the standard deviation.\\
The standard deviation has the same units as $X$.\\
If you pull a constant out of a standard deviation, it doesn't get squared.

\subsubsection*{Example-variance}
What's the sample variance from the result of a toss of a die?\\
\\
Recall that the expected variable of a die is $E[X]=3.5$.
\bea
E[X^2] &=& 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} = 15.17 \\
Var(X)  &=& E[X^2] - E[X]^2 \\
        &=& 15.17 - 3.5^2 = 2.92
\eea

\subsection*{Interpreting Variances}
Chebyshev's inequality is useful for interpreting variances: \\
The probability $P$ that a random variable $X$ is more than or equal to $k$ standard deviations $\sigma$ from its mean $\mu$ is less than or equal to $1/k^2$ for all distributions.
$$P(|X-\mu| \ge k \sigma) \le \frac{1}{k^2}$$
In other words, the probability that a random variable lies beyond $k$ standard deviations from its mean is less than $1/k^2$.
\bea
2 \sigma \rightarrow 25\% \\
3 \sigma \rightarrow 11.11\% \\
4 \sigma \rightarrow 6.25\% \\
7 \sigma \rightarrow 2.04\% \\
10 \sigma \rightarrow 1\%
\eea
These are upper bounds and the actual probability might be much smaller. With the normal distribution, for example, the probability that a variable lies 3 standard deviations away or further is 1\%.

\subsubsection*{example 1 - interpreting variance}
IQs are often said to be normally distributed with a mean of 100 and a sd of 15.\\
What is the probability of a randomly drawn person having an IQ higher than 160 or below 40?
\bi
\item Thus we want to know the probability of a person being more than 4 standard deviations from the mean.
\item Thus Chebyshev's inequality suggests that this will be no larger than 6\%.
\item IQs distributions are often cited as being bell shaped, in which case this bound is very conservative.
\item The probability of a random draw from a bell curve being 4 standard deviations from the mean is on the order of $10^{-5}$ (one thousandth of one percent).
\ei

\subsubsection*{example 2 - interpreting variance}
A former buzz phrase in industrial quality control is Motorola's "six sigma", whereby businesses are suggested to control extreme events or rare defective parts.\\
\\
Chebyshev's inequality states that the probability of a "Six Sigma" event is less than $1/6^2 = 2.78\%$.\\
\\
If a bell curve is assumed, then the probability is on the order of $10^{-9}$ or one ten millionth of a percent.\\
\\

\subsection*{Moments}
Variances and Means are both types of Moments of a distribution, and they are the first two moments, and the most important moments of a distribution.






\end{document}