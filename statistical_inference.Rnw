\documentclass{article}
%%%%% statistical_inference.Rnw
%%%%% LaTeX / Sweave notes by Stephen Franklin, May 2014,
%%%%% for Statistical Inference - Coursera / Johns Hopkins - Prof. Brian Caffo

%%%%%% my custom command definitions %%%%%%

%% \mathbf sucks because it screws up other math mode directives.  Instead
%% use \boldsymbol (from AMS) since it puts stuff in bold italics.
\newcommand{\bsymb}[1]{\boldsymbol{#1}}
\newcommand{\bea}{\begin{eqnarray*}}
\newcommand{\eea}{\end{eqnarray*}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\si}{\subitem}
\newcommand{\ssi}{\subsubitem}
\newcommand{\tn}{\textnormal}  % in math mode text will use font of document.
    %% \textrm = roman font, \tt=\texttt = typewriter font
\setlength{\parskip}{12pt}

\begin{document}
\SweaveOpts{concordance=TRUE}

\section*{Statistical Inference Notes}
Statistical Inference is the process of drawing formal conclusions;
as settings where one wants to infer facts about a population using noisy statistical data where uncertainty must be accounted for.\\
\\
A strong inference may affect the study itself. Researchers may decide it is ethically responsible to halt the study in light of strongly positive or negative preliminary results.

\subsection*{Considerations of a study include:}
\begin{itemize}
    \item Is the sample representative of the target population?
    \item Is the sample representative of the target population?
    \item Are there known and observed, known and unobserved, or unknown and unobserved variables that contaminate our conclusions?
    \item Is there systematic bias created by missing data or the design or conduct of the study?
    \item What randomness exists in the data and how do we use or adjust for it?  
        \subitem Randomness can be explicit via randomization or random sampling,
        \subitem or implicit as the aggregation of many complex unknown processes.
    \item Are we trying to estimate an underlying mechanistic model of phenomena under study?
\end{itemize}

\subsection*{Example goals of Inference:}
\begin{itemize}
    \item Estimate or quantify the uncertainty of an estimate.
    \item Determine whether the quantity is a benchmark value ("Is the treatment effective?")
    \item Infer a mechanistic relationship when quantities are measured with noise ("What is the slope for Hooke's Law?")
    \item Determine the overall impact of a policy a phenomenon, as opposed to revealing the mechanism that describes it.
\end{itemize}

\subsection*{Some tools of the trade:}
\begin{itemize}
    \item Randomization: balances unobserved variables that may confound inferences, i.e between the control and treated.
    \item Random Sampling: data obtained is representative of the population of interest.
    \item Sampling models: a model for the sampling process is created because Randomization and Random Sampling are often impossible. "iid".
    \item Hypothesis Testing: Decision making in the presence of uncertainty.
    \item Confidence Intervals: Quantify the uncertainty in estimation.
    \item Probability Models: A formal connection between the data and the population of interest; assumed or approximated.
    \item Study Design: Designing the experiment to minimize bias and variability. Of course randomized is the best.
    \item Nonparametric Bootstrapping: The process of using the data (with minimal Probability Model assumptions) to create inferences.
    \item Permutation, Randomization, and Exchangability Testing: The process of using data permutations to perform inferences.
\end{itemize}

\subsection*{Thinking Styles:}
Data scientists use some combination of two opposing modes of inference (as well as other schools of thought):
\begin{itemize}
    \item Frequency Inference: What should I decide given the long-run-proportion of events in independent, identically distributed repetitions?
    \item Bayesian Inference: Given my subjective beliefs, and the new objective information from the data, how should I modify my beliefs?
\end{itemize}

This class will focus on frequency style analyses, beginning with probability modeling.

\section*{Probability}
\subsection*{Notation}
\begin{itemize}
    \item $\Omega$: The sample space; the collection of all possible outcomes.
        \subitem e.g. die roll: $\Omega = \{1,2,3,4,5,6\}$
    \item $E$: (Or another letter.) An event; a subset of $\Omega$.
        \subitem e.g. die roll is even: $E = \{2,4,6\}$
    \item $\omega$: (Or another letter.) An elementary or simple event is a particular result of an experiment.
        \subitem e.g. die roll is a four: $\omega = 4$
    \item $\emptyset$: The null event or empty set.
\end{itemize}

\subsection*{Common Set Operations}
\bi
\item $\omega \in E$: The simple event $\omega$ is an element of set $E$.  
    \subitem Implies that $E$ occurs when $\omega$ occurs.
    \subitem e.g. If I rolled a 4, then I rolled an even number.  
\item $\omega \notin E$: The simple event is not an element of the set.
    \subitem Implies that $E$ doesn't occur when $\omega$ occurs.
\item $E \subset F$: The set $E$ is a subset of set $F$.
    \subitem The occurrence of $E$ implies the occurrence of $F$.
\item $E \cap F$: Intersection; the set containing the elements that are common to both $E$ and $F$.
    \subitem Implies an event for which both $E$ and $F$ occur.
\item $E \cup F$: Union; the set containing all the elements in both $E$ and $F$.
    \subitem Implies an event for which $E$ or $F$ or both occur.
\item $E \cap F = \emptyset$: $E$ and $F$ are mutually exclusive; both cannot occur; no intersection.
\item $E^c$ or $\bar{E}$: The event for which $E$ doesn't occur.
\ei

\subsection*{Probability}
A probability measure, $P$, is a function from the sample space $\Omega$ for which the following hold true:\\
\begin{enumerate}
\item For an event $E \subset \Omega, 0 \le P(E) \le 1$.
    \subitem For an event in a subset of the sample space, 
    \subitem the probability is between 0 and 1.
\item $P(\Omega) = 1$.
    \subitem The probability of an event in the entire sample space is 1.
\item If $E_1 \cap E_2 = \emptyset, P(E_1 \cup E_2) = P(E_1) + P(E_2)$.
    \subitem If $E_1$ and $E_2$ have no intersection,
    \subitem then the probability of their union is the sum of their probabilities.
\item \#3 implies finite additivity:
    $$P(\cup^n_{i=1}A_i)=\sum_{i=1}^{n} P(A_i)$$
    \subitem where the ${A_i}$ are mutually exclusive.
    \subitem If you union up a bunch of mutually exclusive events,
    \subitem then the union can become a sum.
\end{enumerate}

\subsection*{Example Consequences}
Andrey Nikolaevich Kolmogorov in 1933 formulated these eight axioms and said that these are all you need to have probability behave as we think it should.
\bi
\item $P(\emptyset)=0$
    \subitem also $P(\Omega)=1$
\item $P(E)=1-P(\bar{E})$
\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\item if $A \subset B$ then $P(A) \le P(B)$
\item $P(A \cup B) = 1-P(\bar{A} \cap \bar{B})$
\item $P(A \cap \bar{B}) = P(A) - P(A \cap B)$
\item $P(\cup^n_{i=1} E_i) \le \sum_{i=1}^n P(E_i)$
\item $P(\cup^n_{i=1} E_i) \ge \tn{max}_i P(E_i)$
\ei

\subsection*{Random Variables}
\begin{enumerate}
\item discrete: $P(X=k)$
\item continuous: $P(X \in A)$
\end{enumerate}

\subsection*{PMF - Probability Mass Function}
The probability mass function describes a discrete random variable. A PMF evaluated at a value corresponds to the probability that a random variable takes that value. To be a valid PMF, a function $p$ must satisfy:
\begin{enumerate}
\item $p(x) \ge$ 0 for all $x$.
\item $\sum_x p(x) =1$
\end{enumerate}
where the sum is taken over all possible values for $x$.

\subsubsection*{Example 1:}
Let $X$ be the result of a coin flip where $X=\{0,1\}$ or \{heads,tails\}.
\bea
p(x) &=& (1/2)^x (1/2)^{1-x} \tn{ for } x=0,1 \\
p(1) &=& (1/2)^1 (1/2)^{1-1} \ = \ 1/2 \\
p(0) &=& (1/2)^0 (1/2)^{1-0} \ = \ 1/2
\eea

\subsubsection*{Example 2:}
Suppose the coin isn't fair. Let $\theta$ be the probability of a head expressed as a proportion (between 0 and 1), say 0.25.
\bea
p(x) &=& \theta^x (1-\theta)^{1-x} \tn{ for } x=0,1 \\
p(1) &=& \theta^1 (1-\theta)^{1-1} \ = \ \theta \\
p(0) &=& \theta^0 (1-\theta)^{1-0} \ = \ 1-\theta
\eea
So if heads is $\theta = 0.25$, then tails is $1-0.25 = 0.75$.

\subsection*{PDF - Probability Density Function}
The probability density function describes a continuous random variable. The area under the PDF line corresponds to a probability for a group of values of the variable.\\
To be a valid PDF, a function $f$ must satisfy:
\begin{enumerate}
\item $f(x) \ge$ for all $x$.
\item The area under $f(x)$ is one.
\end{enumerate}
A single value of a continuous random variable corresponds to an area of 0.\\
Instead, we refer to a probability of a region of values (between $a$ and $b$).
The fact that the probability of a single specific value is 0 is a consequence of modeling the probability as a truly continuous entity, an infinite decimal expansion, wherein we cannot attain infinite precision. In other words, there is no such thing as a single specific value.\\
\\
The Gaussian Bell Curve is the most famous example of a probability density function.

\subsubsection*{Example 1:}
Suppose that the proportion of help calls that get addressed in a random day by a help line is given by this probability density:
$$
f(x) = \left\{ \begin{array}{rl}
 2x &\mbox{ for $1 > x > 0$} \\
 0 &\mbox{ otherwise}
        \end{array} \right.
$$
Is this a mathematically valid density?
<<pdf_example_1, fig=T, echo=T >>=
x <- c(-0.5, 0, 1, 1, 1.5)
y <- c(0, 0, 2, 0, 0)
#par(pin = c(2,2), mar = (c(2, 2, 2, 1) + 0.1))
plot(x,y, lwd=3, frame=F, type="l")
abline(v=0.5)
abline(v=0.75)
@
\\
If we ask "What percentage of days do between 50\% and 75\% of the calls get addressed?," then the area under within the lines corresponds to the percentage of days that that range of calls get addressed.\\
\\
It's roughly $0.25 \cdot 1.25 = 0.31$ or \\
"31\% of the time (in days) between 50\% and 75\% of calls are addressed on a day."

\subsubsection*{Example 2:}
What is the probability that 75\% or fewer calls get addressed?
<<pdf_example_2, fig=T, echo=T >>=
x <- c(-0.5, 0, 1, 1, 1.5)
y <- c(0, 0, 2, 0, 0)
#par(pin = c(2,2))
plot(x,y, lwd=3, frame=F, type="l")
abline(v=0)
abline(v=0.75)
@
\\
The area is $0.5 (0.75 \cdot 1.5) = 0.5625$. \\
\\
In R, the command \emph{pbeta()} of x will return the probability of being lower than x:
<<echo=T>>=
pbeta(0.75, 2, 1)
@

\subsection*{CDF and Survival Function}
The Cumulative Distribution Function of a random variable $X$ is defined as the function:
$$F(x) = P(X \le x)$$
This definition applies to both discrete and continuous variables.\\
\\
The Survival Function of a random variable $X$ is defined as:
$$S(x) = P(X > x)$$
Notice that $S(X) = 1 - F(X)$.\\
\\
For continuous variables the PDF is the derivative of the CDF.

\subsubsection*{Example:}
What are the Survival Function and the CDF from the density considered previously?\\
\\
For $1 \ge x \ge 0$ \\
(We must exclude unanswered calls, i.e. outside of $x=[0,1]$, for this density to make sense),
\bea
F(x)    &=& P(X \le x) \ =\  \frac{1}{2} \ base \times height \\
        &=& \frac{1}{2} (x) \times (2x) \ = \ x^2 \\
S(x)    &=& 1-x^2
\eea
\\
In R, we can use the \emph{pbeta()} function to get the probabilities:\\
<<echo=TRUE>>=
pbeta(c(0.4,0.5,0.6), 2, 1)
@

\subsection*{Quantiles}
The $\alpha^{th}$ quantile of a distribution with the distribution function $F$ is the point $x_{\alpha}$ so that:
$$F(x_{\alpha}) = \alpha$$
A percentile is simply a quantile with $\alpha$ expressed as a percent. \\
\\
The median is the $50^{th}$ percentile, or the $0.5^{th}$ quantile, and can be expressed as $x_{0.5}$. \\
\\
Consider that 0.5 of the area lies below $x_{0.5}$ and 0.5 of the area lies above it. We can express that as: $0.5 = F(x_{0.5})$. \\
\\
Recall that the cumulative distribution function for our example is $F = x^2$. \\
To find $x_{0.5}$, we must invert the function $F$.
\bea
x \ = \ F^{-1}(x) \ = \ \sqrt{x} \\
x_{0.5} \ = \ \sqrt{0.5} \ = \ 0.707
\eea \\
Therefore, about 70\% of calls being answered on a random day is the median.\\
\\
In general, the distribution function describes a point $x_{\alpha}$ along a density for which the area $\alpha$ lies below it, and the area $1-\alpha$ lies above it.\\
\\
In R, we can approximate the quantiles for common distributions with the function \emph{qbeta()}:
<<echo=TRUE>>=
qbeta(0.5,2,1)
@
\subsection*{Probability Summary}
A probability model uses assumptions to connect the sample data (which is limited) to the population.  We want connect the sample median to the population median; the population median is the estimand, and the sample median is the estimator.

\section*{Expected Values - Discrete Random Variables}
The Expected Value is the mean of a random variable, and is the center of its distribution.\\
\\
For a discrete random variable $X$ with PMF p(x), it is defined as:
$$E[X] = \sum_x xp(x)x$$
\\
We use the square brackets [] to denote the expected value.\\
\\
$E[X]$ represents the center of mass of a collection of locations and weights, $\{x,p(x)\}$.

\subsubsection*{R Example - Expected Value}
This example uses R, the libraries "Manipulate" and "UsingR", and the UsingR dataset "Galton.
<<example_manipulate,echo=TRUE,>>=
library(manipulate)
library(UsingR)
data(galton)
myHist <- function(mu){
    hist(galton$child, col="blue", breaks=100)
    lines(c(mu,mu), c(0,150), col="red", lwd=5)
    mse <- mean((galton$child -mu)^2 )
    text(63,150, paste("mu = ",mu ))
    text(63,140, paste("Imbalance = ", round(mse,2) ))
}
#manipulate(myHist(mu), mu=slider(62,74, step=0.5))
@
The manipulate() library makes interactive plots, so it won't work in this .pdf document (and it's commented out) but the histogram looks like this:\\
<<echo=F, fig=TRUE>>=
    hist(galton$child, col="blue", breaks=100)
    meanChild <- mean(galton$Child)
    lines(rep(meanChild, 100), seq(0,150, length=100), col="red", lwd=5)
@

\subsubsection*{Example - expected value of a discrete variable}
Suppose that a die is rolled and X is the number that is face up. \\
What is the expected value of X?\\
\\
$$E[X] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5$$

\subsection*{Expected Value - Continuous Random Variables}
For a continuous random variable $X$ with a density $f$ the expected value is defined as:
$$E[X] = \tn{ the area under the function } tf(t)$$
This definition borrow from the definition of center of mass for a continuous body.

\subsubsection*{Example - expected value of a continuous variable}
Consider a density where $f(x) = 1$ for $x$ between 0 and 1.\\
Is this a valid density?\\
Suppose $X$ follows this density. What is its expected value?\\
\\
$f(x)$ describes a block shaped density.\\
It's valid because $y > 0$ everywhere that $x$ is positive,\\
and it has a calculable area (base x height = 1 x 1 = 1).\\
\\
The function $tf(t)$ in this case is a right triangle where $x=y$.\\
We can integrate that to find the area, or we can simply compute the area  of a triangle: (1/2 x base x height = 0.5).\\
So 0.5 is the mean and the expected value, and it is also intuitively the center of mass for the block.

\subsection*{Rules of Expected Values}
\bi
\item The expected value is a linear operator.
\item If $a$ and $b$ are not random and $X$ and $Y$ are two random variables, then:
    \subitem $E[aX+b] = aE[X]+b$
    \subitem $E[X+Y] = E[X]+E[Y]$
\item but:
    \subitem $E[X \cdot Y] \ne E[X] \cdot E[Y]$
    \subitem $E[X^2] \ne E[X]^2$
\ei

\subsubsection*{examples - rules of expected values}
You flip a coin $X$ and simulate a uniform random number $Y$.\\
What is the expected value of their sum?\\
\\
The random uniform density is the block-like density which yields numbers between 0 and 1; the expected value of the uniform density is 0.5.\\
The coin flip yields only 0 or 1, and its expected value is also 0.5.
$$E[X+Y] = E[X]+E[Y] = 0.5 + 0.5 = 1$$\\
You roll a die twice. What is the expected value of the average? \\
\\
Let $X_1$ and $X_2$ be the results of two dice rolls. The average of course is their sum divided by their count.
$$E[(X_1+X_2)/2] = \frac{1}{2}(E[X_1]+E[X_2]) = \frac{1}{2}(3.5 + 3.5) = 3.5$$
\\
That case can be generalized:\\
Let $X_i$ for $i = 1, ..., n$ be a collection of random variables, each from a distribution  with mean $\mu$. \\
Then the expected value of the sample average of $X_i$ is found by:
\bea
E \left[ \frac{1}{n} \sum_{i=1}^n X_i \right]
&=& \frac{1}{n} E \left[ \sum_{i=1}^n X_i \right] \\
&=& \frac{1}{n} \sum_{i=1}^n E \left[ X_i \right] \\
&=& \frac{1}{n} \sum_{i=1}^n \mu = \mu
\eea
So if all the variables have the same mean, then their average also has that mean.\\
Therefore, the expected value of the sample average is the population mean as well; it's exactly what we would like it to be.\\
When the expected value of an estimator is what it is trying to estimate, we say that the estimator is unbiased.

\subsection*{Variance}
The variance of a random variable is a measure of spread.\\
\\
If $X$ is a random variable with mean $\mu$, the variance is defined as:
$$Var(X) = E[(X-\mu)^2]$$
the expected (squared) distance from the mean.\\
\\
Densities with a higher variance are more spread out then densities with lower variance.\\
\\
Computational form:
$$Var(X) = E[X^2] - E[X]^2$$
\\
If $a$ is constant then $Var(aX) = a^2 Var(X)$.\\
If you pull a constant out of a variance, the constant gets squared.\\
\\
The square root of the variance is the standard deviation.\\
The standard deviation has the same units as $X$.\\
If you pull a constant out of a standard deviation, it doesn't get squared.

\subsubsection*{Example-variance}
What's the sample variance from the result of a toss of a die?\\
\\
Recall that the expected variable of a die is $E[X]=3.5$.
\bea
E[X^2] &=& 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} = 15.17 \\
Var(X)  &=& E[X^2] - E[X]^2 \\
        &=& 15.17 - 3.5^2 = 2.92
\eea

\subsection*{Interpreting Variances}
Chebyshev's inequality is useful for interpreting variances: \\
The probability $P$ that a random variable $X$ is more than or equal to $k$ standard deviations $\sigma$ from its mean $\mu$ is less than or equal to $1/k^2$ for all distributions.
$$P(|X-\mu| \ge k \sigma) \le \frac{1}{k^2}$$
In other words, the probability that a random variable lies beyond $k$ standard deviations from its mean is less than $1/k^2$.
\bea
2 \sigma \rightarrow 25\% \\
3 \sigma \rightarrow 11.11\% \\
4 \sigma \rightarrow 6.25\% \\
7 \sigma \rightarrow 2.04\% \\
10 \sigma \rightarrow 1\%
\eea
These are upper bounds and the actual probability might be much smaller. With the normal distribution, for example, the probability that a variable lies 3 standard deviations away or further is 1\%.

\subsubsection*{example 1 - interpreting variance}
IQs are often said to be normally distributed with a mean of 100 and a sd of 15.\\
What is the probability of a randomly drawn person having an IQ higher than 160 or below 40?
\bi
\item Thus we want to know the probability of a person being more than 4 standard deviations from the mean.
\item Thus Chebyshev's inequality suggests that this will be no larger than 6\%.
\item IQs distributions are often cited as being bell shaped, in which case this bound is very conservative.
\item The probability of a random draw from a bell curve being 4 standard deviations from the mean is on the order of $10^{-5}$ (one thousandth of one percent).
\ei

\subsubsection*{example 2 - interpreting variance}
A former buzz phrase in industrial quality control is Motorola's "six sigma", whereby businesses are suggested to control extreme events or rare defective parts.\\
\\
Chebyshev's inequality states that the probability of a "Six Sigma" event is less than $1/6^2 = 2.78\%$.\\
\\
If a bell curve is assumed, then the probability is on the order of $10^{-9}$ or one ten millionth of a percent.\\
\\

\subsection*{Moments}
Variances and Means are both types of Moments of a distribution, and they are the first two moments, and the most important moments of a distribution.


\section*{Independence}
\subsection*{Independent Events}
Two events $A$ and $B$ are independent if
$$P(A \cap B) = P(A)P(B)$$
Two random variables $X$ and $Y$ are independent if for any two sets $A$ and $B$
$$P([X \in A] \cap [Y \in B]) = P([X \in A]) P ([Y \in B])$$
If $A$ is independent of $B$ then:
\bi
\item $A^c$ is independent of $B$.
\item $A$ is independent of $B^c$.
\item $A^c$ is independent of $B^c$.
\ei

\subsubsection*{example - independent events}
What is the probability of getting two consecutive heads?\\
\bi
\item $A = \{\tn{Head on flip 1}\} \approx P(A) = 0.5$
\item $B = \{\tn{Head on flip 2}\} \approx P(B) = 0.5$
\item $A \cap B = \{\tn{Head on flip 1 and 2}\}$
\item $A \cap B = P(A)P(B) = 0.5 \cdot 0.5 = 0.25$
\ei
The multiplication of probabilities is only valid for the intersection of  independent events. If for any reason, known or unknown, the events are dependent then muliplying the probabilities isn't appropriate.\\
An example is the Dr. Meadow SIDS testimony in which a mother was convicted of murder after two children died of SIDS.  Dr. Meadow calculated the probability of SIDS occurring twice in the same household as if they were independent events, however SIDS could have a genetic or environmental component which would mean that the events are not independent.\\
\\
Thus, $P(A_1 \cap A_2)$ is not necessarily equal to $P(A_1)P(A_2)$.

\subsection*{Joint Distribution}
If a collection of random variables $X_1,X_2,...,X_n$ are independent, then their joint distribution is the product of their individual densities or mass functions.\\
That is, if $f_i$ is the density for random variable $X_i$, we have that
$$f(x_1,...,x_n) = \prod_{i=1}^n f_i(x_i)$$

\subsection*{IID Random Variables}
 Independent and identically distributed random variables.
 Identically distributed means that they come from the same distribution.
 Coin flips are IID.\\
iid random variables are the default model for random samples. We will assume our data are iid if we assume it is random even if it hasn't been sampled randomly.\\
Most of the important theories of statistics are founded on the assumption that variables are iid.

\subsubsection*{example - iid}
Suppose we flip a biased coin with success probability $p\ n$ times, what is the joint density of the collection of outcomes?\\
\\
These random variables are iid with densities $p^{x_i}(1-p)^{1-x_i}$, therefore:
\bea
f(x_1,...,x_n)  &=& \prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} \\
                &=& p^{\sum x_i} (1-p)^{n-\sum x_i}
\eea
(To be clear, we're putting the summations in the exponents.)\\
\\
That implies that the order of the sequence isn't important, i.e. p(1,1,0,0) is the same as p(0,1,0,1). The probability depends only on the total number of successes and failures.

\subsection*{Correlation}
The covariance between two random variables $X$ and $Y$ is defined as
$$Cov(X,Y) = E[(X-\mu_x)(Y-\mu_y)] = E[XY]-E[X]E[Y]$$
 where $\mu$ is the mean.\\
 Covariance is a measure of how two variables are linearly unrelated.
 \begin{enumerate}
 \item $Cov(X,Y) = Cov(Y,X)$
 \item $Cov(X,Y)$ can be positive or negative.
 \item $|Cov(X,Y)| \le \sqrt{Var(X)Var(Y)}$
    \subitem where $\sqrt{Var(X)Var(Y)} = sd(X)sd(Y)$
 \end{enumerate}

\noindent That third statement implies correlation:
$$Cor(X,Y) = Cov(X,Y) / \sqrt{Var(X)Var(Y)}$$
which has the following properties:
\begin{enumerate}
\item $-1 \le Cor(X,Y) \le 1$
\item $Cor(X,Y) = \pm 1$ if and only if $X=a+bY$ for some constants $a$ and $b$.
\item $Cor(X,Y)$ is unitless.
    \subitem sd has units of X or Y.
\item $X$ and $Y$ are uncorrelated if $Cor(X,Y)=0$
    \subitem They are also uncorrelated if $Cov(X,Y)=0$.
\item $X$ and $Y$ are more positively correlated the closer $Cor(X,Y)$ is to 1.
\item $X$ and $Y$ are more negatively correlated the closer $Cor(X,Y)$ is to -1.
\end{enumerate}
These properties describe the population correlation, which is a statement about the joint population density of the random variables $X$ and $Y$. The sample correlation is an estimate of the population correlation. \par

\noindent Let ${X_i}_{i=1}^n$ be a collection of random variables:
\bi
\item When the ${X_i}$ are uncorrelated:
$$Var \left( \sum_{i=1}^n a_i X_i +b \right) = \sum_{i=1}^n a_i^2 Var(X_i)$$
\subitem The constant $a$ is pulled out and squared.
\subitem The constant $b$ is irrelevant because shifting things doesn't affect variance.
\item A commonly used subcase from this property is that if a collection of random variables ${X_i}$ are uncorrelated, then the variance of the sum is the sum of the variances:
$$Var \left( \sum_{i=1}^n X_i \right) = \sum_{i=1}^n Var(X_i)$$
\subitem ${X_i}$ must be independent.  If they aren't indepedent, then that property isn't true.
\item Therefore, it is sums of variances that tend to be useful, not sums of standard deviations. In other words, the standard deviation of the sum of a bunch of independent random variables is the square root of the sum of the variances, not the sum of the standard deviations.
\ei

\subsection*{Sample Mean $\bar{X}$}
Suppose ${X_i}$ are iid with variance $\sigma^2$:
\bea
Var(\bar{X})    &=& Var \left( \frac{1}{n} \sum_{i=1}^n X_i \right) \\
                &=&  \frac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \\
                &=&  \frac{1}{n^2} \sum_{i=1}^n Var \left(X_i \right) \\
                &=&  \frac{1}{n^2} n\sigma^2 \\
                &=&  \frac{\sigma^2}{n}
\eea
where $\bar{X}$ is the Sample Mean of the random variable's values.\par
\noindent Suppose we had 10 dice and rolled them and took the average $\bar{X}$. $\bar{X}$ is a random number and it has a probability mass function: it can be an integer from 1 to 6, and will likely be a bell-shaped curve. We know the center of the distribution is at 3.5 for a six-sided die.
We now know that the sample mean variance has to be the variance $\sigma^2$ of a single die divided by the number of dice $n$.
And if we take the square root of the sample mean variance, we get the standard error $\sigma/\sqrt{n}$

\bi
\item $\bar{X}=\frac{\sigma^2}{n}$ when $X_i$ are independent with common variance.
\item $\frac{\sigma}{\sqrt{n}}$ is the standard error of the sample mean.
\item The standard error of the sample mean is the standard deviation of the distribution of the sample mean.
\item $\sigma$ is the standard deviation of the distribution of a single observation.
\item The sample mean has to be less variable than a single observation, therefore it's reasonable that its standard deviation is divided by some amount related to the number of observations; that amount is $\sqrt{n}$.
\item Both the standard deviation and the standard error have units of standard deviation. Standard error is a measure of the variability of the average of observations. Standard deviation is a measure of the variability of individual observations.
\ei

\subsection*{Sample Variance $s^2$}
Sample variance is the sample average squared deviation from the empirical mean:
$$s^2 = \frac{\sum_{i=1}^n (X_i - \bar{X})^2}{n-1}$$
\bi
\item The sample variance is an estimator of variance $\sigma^2$.
\item Here is a version that's quicker for calculation:
$$s^2 = \frac{\sum_{i=1}^n X_i^2 - n\bar{X}^2}{n-1}$$
    \subitem which is analagous to $E[X^2] -E[X]^2$ that approximates the variance for the population calculation.
\item The sample variance is (nearly, except for the -1) the mean of the squared deviations from the mean.
\ei

\subsection*{The sample variance is unbiased $n-1$}
To explain why we use $n-1$ instead of $n$ in the denominator, let's look at the expected value of the numerator.  First, recall the formula for the variance of a random variable:
$$Var(X) = E[X^2] - E[X]^2$$
Thus:
$$Var(X)+E[X]^2 = E[X^2]$$
And recall that the mean is $\mu$.
Therefore if we want to calculate the expected value of the sample mean squared $E[\bar{X}^2]$, we can plug in the expected value of the mean squared $\mu^2$ plus the variance of the mean $Var(\bar{X})$.
Likewise, we can calculate $E[X_i^2]$ by substituting it with $\mu^2$ and adding $Var(X_i)$.
\bea
E \left[ \sum_{i=1}^n X_i^2 - n\bar{X}^2 \right]
    &=& \sum_{i=1}^n E[X_i^2] - nE[\bar{X}^2] \\
    &=& \sum_{i=1}^n \left\{ Var(X_i) + \mu^2 \right\} - n\left\{ Var(\bar{X})+\mu^2 \right\} \\
    &=& \sum_{i=1}^n \left\{ \sigma^2 + \mu^2 \right\} - n\left\{ \sigma^2/n + \mu^2 \right\} \\
    &=& n\sigma^2 + n\mu^2 - \sigma^2 - n\mu^2 \\
    &=& (n-1)\sigma^2
\eea
I got lost in there, but basically the $n-1$ term is the correct denominator to avoid a bias in the sample mean. \par

\noindent Some points to avoid confusion.
\bi
\item Suppose $X_i$ are iid with mean $\mu$ and variance $\sigma^2$.
\item $s^2$ estimates $\sigma^2$.
\item The calculation of $S^2$ involves dividing by $n-1$.
\item $s/\sqrt{n}$ estimates the standard error of the mean $\sigma/\sqrt{n}$.
\item $s^2/n$ estimates the variance of the mean $\sigma^2/n$
\item $s/\sqrt{n}$ is called the sample standard error (of the mean).
\item Don't confuse that $/\sqrt{n}$ with the $/(n-1)$ which is only for calculating $s^2$.
\ei

\subsubsection*{R Example - Sample Variance}
This example uses R, the libraries "Manipulate" and "UsingR", and the UsingR dataset "father.son".
<<example_manipulate,echo=TRUE,>>=
library(UsingR)
data(father.son)
x <- father.son$sheight
n <- length(x)
hist(father.son$sheight,n,breaks=10,col="skyblue")
round(c(sum((x-mean(x))^2)/(n-1), var(x), var(x)/n,
        sd(x), sd(x)/sqrt(n)),2)
@
where we have a list of:
\begin{enumerate}
\item $s^2$, manual calculation of sample variance of heights ($\tn{inches}^2$).
\item R calculation of $s^2$.
\item Variance of the mean of heights ($\tn{inches}^2$).
\item Standard deviation of heights (inches).
\item Sample standard error of the mean of heights (inches).
\end{enumerate}

\end{document}
